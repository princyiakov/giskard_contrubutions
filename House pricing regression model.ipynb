{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YtkngBcM_J1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![giskard_logo.png](https://raw.githubusercontent.com/Giskard-AI/giskard/main/readme/Logo_full_darkgreen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a9b17467105f4031a3f9eae70ef4138f",
    "deepnote_cell_height": 134,
    "deepnote_cell_type": "markdown",
    "id": "Y6uigumMyl-s",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# About Giskard\n",
    "\n",
    "Open-Source CI/CD platform for ML teams. Deliver ML products, better & faster. \n",
    "\n",
    "*   Collaborate faster with feedback from business stakeholders.\n",
    "*   Deploy automated tests to eliminate regressions, errors & biases.\n",
    "\n",
    "üè° [Website](https://giskard.ai/)\n",
    "\n",
    "üìó [Documentation](https://docs.giskard.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing `giskard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install giskard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect the external worker in daemon mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!giskard worker start -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Start by creating an ML model üöÄüöÄüöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's create a house pricing model based on Kaggle dataset [(Link](https://raw.githubusercontent.com/Giskard-AI/giskard-client/main/sample_data/regression/house-prices/house_price_updated.csv) to download the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# To download and read the House Pricing Dataset\n",
    "url = 'https://raw.githubusercontent.com/Giskard-AI/examples/main/datasets/house_pricing_regression_model_dataset/house_price_updated.csv'\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Good', 'Average', 'Excellent', 'Fair'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.KitchenQuality.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Declare the type of each column in the dataset(example: category, numeric, text)\n",
    "column_types = {'TypeOfDewelling': 'category',\n",
    "                'BldgType': 'category',\n",
    "                'AbvGroundLivingArea': 'numeric',\n",
    "                'Neighborhood': 'category',\n",
    "                'KitchenQuality': 'category',\n",
    "                'NumGarageCars': 'numeric',\n",
    "                'YearBuilt': 'numeric',\n",
    "                'RemodelYear':  'numeric',\n",
    "                'ExternalQuality': 'category',\n",
    "                'LotArea': 'numeric',\n",
    "                'LotShape': 'category',\n",
    "                'Fireplaces': 'numeric',\n",
    "                'NumBathroom': 'numeric',\n",
    "                'Basement1Type': 'category',\n",
    "                'Basement1SurfaceArea': 'numeric',\n",
    "                'Basement2Type': 'category',\n",
    "                'Basement2SurfaceArea': 'numeric',\n",
    "                'TotalBasementArea': 'numeric',\n",
    "                'GarageArea': 'numeric',\n",
    "                '1stFlrArea': 'numeric',\n",
    "                '2ndFlrArea': 'numeric',\n",
    "                'Utilities': 'category',\n",
    "                'OverallQuality': 'category',\n",
    "                'SalePrice': 'numeric'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# feature_types is used to declare the features the model is trained on\n",
    "feature_types = {i:column_types[i] for i in column_types if i!='SalePrice'}\n",
    "\n",
    "# Pipeline to fill missing values, transform and scale the numeric columns\n",
    "numeric_features = [key for key in feature_types.keys() if feature_types[key]==\"numeric\"]\n",
    "numeric_transformer = Pipeline([('imputer', SimpleImputer(missing_values= np.nan, strategy='mean')),\n",
    "                                ('scaler', StandardScaler())])\n",
    "\n",
    "# Pipeline to fill missing values and one hot encode the categorical values\n",
    "categorical_features = [key for key in feature_types.keys() if feature_types[key]==\"category\"]\n",
    "categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values= np.nan, strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore',sparse=False)) ])\n",
    "\n",
    "# Initiate Preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "      ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline for the Random Forest Model\n",
    "reg_random_forest = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', RandomForestRegressor())])\n",
    "\n",
    "# Split the data\n",
    "y = data['SalePrice']\n",
    "X = data.drop(columns=\"SalePrice\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20, random_state = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.858\n"
     ]
    }
   ],
   "source": [
    "# Fit and score your model\n",
    "reg_random_forest.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % reg_random_forest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare data to upload on Giskard\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Upload the model in Giskard üöÄüöÄüöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Initiate a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from giskard import GiskardClient\n",
    "\n",
    "url = \"http://localhost:19000\" #if Giskard is installed locally (for installation, see: https://docs.giskard.ai/start/guides/installation)\n",
    "#url = \"http://app.giskard.ai\" # If you want to upload on giskard URL\n",
    "token = \"YOUR GENERATED TOKEN\" #you can generate your API token in the Admin tab of the Giskard application (for installation, see: https://docs.giskard.ai/start/guides/installation)\n",
    "\n",
    "client = GiskardClient(url, token)\n",
    "\n",
    "# your_project = client.create_project(\"project_key\", \"PROJECT_NAME\", \"DESCRIPTION\")\n",
    "# Choose the arguments you want. But \"project_key\" should be unique and in lower case\n",
    "house_pricing = client.create_project(\"house_pricing\", \"House pricing model\", \"Project to predict house prices\")\n",
    "\n",
    "#If you've already created a project with the key \"house_pricing\" use\n",
    "# house_pricing = client.get_project(\"house_pricing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Upload your model and a dataset (see [documentation](https://docs.giskard.ai/start/guides/upload-your-model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "house_pricing.upload_model_and_df(\n",
    "    prediction_function=reg_random_forest.predict, # Python function which takes pandas dataframe as input and returns probabilities for classification model OR returns predictions for regression model\n",
    "    model_type='regression', # \"classification\" for classification model OR \"regression\" for regression model\n",
    "    df=test_data, # The dataset you want to use to inspect your model\n",
    "    column_types=column_types, # A dictionary with columns names of df as key and types(category, numeric, text) of columns as values\n",
    "    target='SalePrice', # The column name in df corresponding to the actual target variable (ground truth).\n",
    "    feature_names=list(feature_types.keys()), # List of the feature names of prediction_function\n",
    "    model_name='random_forest_v1', # Name of the model\n",
    "    dataset_name='test_data' # Name of the dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### üåü If you want to upload a dataset without a model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For example, let's upload the train set in Giskard, this is key to create drift tests in Giskard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "house_pricing.upload_df(\n",
    "    df=train_data, # The dataset you want to upload\n",
    "    column_types=column_types, # All the column types of df\n",
    "    target=\"SalePrice\", # Do not pass this parameter if dataset doesn't contain target column\n",
    "    name=\"train_data\"  # Name of the dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can also upload new production data to use it as a validatation set for your existing model. In that case, you might not have the ground truth target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "production_data = data.drop(columns=\"SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "house_pricing.upload_df(\n",
    "    df=production_data, # The dataset you want to upload\n",
    "    column_types=feature_types, # All the column types without the target\n",
    "    name=\"production_data\" # Name of the dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### üåü If you just want to upload a model without a dataframe \n",
    "\n",
    "This happens for instance when you built a new version of the model and you want to inspect it using a validation dataframe that is already in Giskard\n",
    "\n",
    "For example, let's create a second version of the model using the catboost library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "X['Basement1Type'] = X['Basement1Type'].fillna(\"\")\n",
    "X['Basement2Type'] = X['Basement2Type'].fillna(\"\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20, random_state = 30)\n",
    "\n",
    "model = CatBoostRegressor(iterations=2,\n",
    "                           learning_rate=1,\n",
    "                           depth=2)\n",
    "\n",
    "model.fit(X_train, y_train, cat_features=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prediction_function(X):\n",
    "  X['Basement1Type'] = X['Basement1Type'].fillna(\"\")\n",
    "  X['Basement2Type'] = X['Basement2Type'].fillna(\"\")\n",
    "  return model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "house_pricing.upload_model(\n",
    "    prediction_function=prediction_function, # Python function which takes pandas dataframe as input and returns probabilities for classification model OR returns predictions for regression model\n",
    "    model_type='regression', # \"classification\" for classification model OR \"regression\" for regression model\n",
    "    feature_names=list(feature_types.keys()), # List of the feature names of prediction_function\n",
    "    name='catboost', # Name of the model\n",
    "    validate_df=train_data, # Optional. Validation df is not uploaded in the app, it's only used to check whether the model has the good format\n",
    "    target=\"SalePrice\", # Optional. target should be a column of validate_df. Pass this parameter only if validate_df is being passed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c49894d61f544e8f88030b7be8078c6b",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 96
    },
    "deepnote_cell_height": 114,
    "deepnote_cell_type": "markdown",
    "id": "gBg6NGguyl-3",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Happy Exploration ! üßë‚ÄçüöÄ"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "House Pricing Model.ipynb",
   "provenance": []
  },
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_app_layout": "article",
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6e7ea85d-f19e-4d05-90a4-44b7668fd037",
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
